{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "r\"\"\"\n",
    "Module defines a class and routines for managing storm best-track type input and\n",
    "testing reconstructed wind and pressure fields.  Additionally some support for\n",
    "ensembles of storms from various providers is also included.\n",
    "\n",
    "The primary class of interest in the module is the `Storm` class that\n",
    "facilitates dealing with various best-track formats found around the world and\n",
    "the expected GeoClaw storm format that is read into the FORTRAN code.  The basic\n",
    "workflow in a `setrun.py` file would do the following:\n",
    "\n",
    "1. Create a `Storm` object by reading in from a file::\n",
    "\n",
    "    storm = clawpack.geoclaw.surge.storm.Storm(\"my_storm.txt\", file_format='ATCF')\n",
    "\n",
    "2. Write out the storm object created into the GeoClaw format::\n",
    "\n",
    "    storm.write(\"my_geoclaw_storm.txt\", file_format=\"geoclaw\")\n",
    "\n",
    "3. Specify the path to the GeoClaw formatted storm file, in this case\n",
    "   \"my_geoclaw_storm.txt\".\n",
    "\n",
    ":Formats Supported:\n",
    "    - GeoClaw (fully)\n",
    "    - ATCF (reading only)\n",
    "    - HURDAT (reading only)\n",
    "    - IBTrACS (reading only)\n",
    "    - JMA (reading only)\n",
    "    - IMD (planned)\n",
    "    - tcvitals (reading only)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from six.moves import range\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import datetime\n",
    "\n",
    "import numpy\n",
    "\n",
    "import clawpack.geoclaw.units as units\n",
    "import clawpack.clawutil.data\n",
    "\n",
    "# =============================================================================\n",
    "#  Common acronyms across formats\n",
    "\n",
    "# ATCF basins with their expanded names\n",
    "# see https://www.nrlmry.navy.mil/atcf_web/docs/database/new/abrdeck.html\n",
    "ATCF_basins = {\"AL\": \"Atlantic\",\n",
    "               \"CP\": \"Central Pacific\",\n",
    "               \"EP\": \"East Pacific\",\n",
    "               \"IO\": \"North Indian Ocean\",\n",
    "               \"SH\": \"Southern Hemisphere\",\n",
    "               \"SL\": \"Southern Atlantic\",\n",
    "               \"LS\": \"Southern Atlantic\",\n",
    "               \"WP\": \"North West Pacific\"}\n",
    "\n",
    "# TCVitals basins with their expanded names\n",
    "# see http://www.emc.ncep.noaa.gov/HWRF/tcvitals-draft.html\n",
    "TCVitals_Basins = {\"L\": \"North Atlantic\",\n",
    "                   \"E\": \"North East Pacific\",\n",
    "                   \"C\": \"North Central Pacific\",\n",
    " \t\t   \"W\": \"North West Pacific\",\n",
    "\t\t   \"B\": \"Bay of Bengal (North Indian Ocean)\",\n",
    "\t\t   \"A\": \"Arabian Sea (North Indian Ocean)\",\n",
    "\t\t   \"Q\": \"South Atlantic\",\n",
    "\t\t   \"P\": \"South Pacific\",\n",
    "\t\t   \"S\": \"South Indian Ocean\"}\n",
    "\n",
    "# Tropical Cyclone Designations\n",
    "# see https://www.nrlmry.navy.mil/atcf_web/docs/database/new/abrdeck.html\n",
    "TC_designations = {\"DB\": \"disturbance\",\n",
    "                   \"TD\": \"tropical depression\",\n",
    "                   \"TS\": \"tropical storm\",\n",
    "                   \"TY\": \"typhoon\",\n",
    "                   \"ST\": \"super typhoon\",\n",
    "                   \"TC\": \"tropical cyclone\",\n",
    "                   \"HU\": \"hurricane\",\n",
    "                   \"SD\": \"subtropical depression\",\n",
    "                   \"SS\": \"subtropical storm\",\n",
    "                   \"EX\": \"extratropical systems\",\n",
    "                   \"IN\": \"inland\",\n",
    "                   \"DS\": \"dissipating\",\n",
    "                   \"LO\": \"low\",\n",
    "                   \"WV\": \"tropical wave\",\n",
    "                   \"ET\": \"extrapolated\",\n",
    "                   \"XX\": \"unknown\"}\n",
    "\n",
    "# HURDAT special designations\n",
    "# see http://www.aoml.noaa.gov/hrd/data_sub/newHURDAT.html\n",
    "hurdat_special_entries = {\"L\": \"landfall\",\n",
    "                          \"W\": \"max wind\",\n",
    "                          \"P\": \"min pressure\",\n",
    "                          \"I\": \"max intensity\",\n",
    "                          \"C\": \"closest approach\",\n",
    "                          \"S\": \"status change\",\n",
    "                          \"G\": \"genesis\",\n",
    "                          \"T\": \"additional track point\"}\n",
    "\n",
    "\n",
    "# Warning for formats that have yet to have a default way to determine crticial\n",
    "# radii from the input data\n",
    "missing_data_warning_str = \"\"\"*** Cannot yet automatically determine the\n",
    "    maximum wind radius.  Will write out GeoClaw\n",
    "    formats but note that these will not work\n",
    "    when running GeoClaw currently without a custom\n",
    "    `max_wind_radius_fill` function passed as argument\n",
    "    to the `write` function.\"\"\"\n",
    "\n",
    "# Warning for not having any time points with both a max wind speed and central\n",
    "# pressure observation\n",
    "missing_necessary_data_warning_str = \"\"\"No storm points in the input file\n",
    "    had both a max wind speed and a central pressure observation.\"\"\"\n",
    "\n",
    "class NoDataError(ValueError):\n",
    "    \"\"\"Exception to raise when no valid data in input file\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "#  Basic storm class\n",
    "class Storm(object):\n",
    "    r\"\"\"\n",
    "    Storm data object\n",
    "\n",
    "    This object contains a time series of time data that describe a particular\n",
    "    storm.  This includes the attributes below and the ability to read from\n",
    "    multiple sources for data such as the U.S. National Hurricane Center (NHC),\n",
    "    the Japanese Meterological Agency (JMA), and the Indian Meteorlogical\n",
    "    Department (IMD).  This class can then write out in any of these formats,\n",
    "    construct the wind and pressure fields using a supported parameterized\n",
    "    model, or output the GeoClaw supported storm format used for running storm\n",
    "    surge simulations.\n",
    "\n",
    "    *TODO:*  Add description of unit handling\n",
    "\n",
    "    :Attributes:\n",
    "     - *t* (list(datetime.datetiem)) Contains the time at which each entry of\n",
    "       the other arrays are at.  These are expected to be *datetime* objects.\n",
    "       Note that when written some formats require a *time_offset* to be set.\n",
    "     - *eye_location* (ndarray(:, :)) location of the eye of the storm.\n",
    "       Default units are in signed decimcal longitude and latitude.\n",
    "     - *max_wind_speed* (ndarray(:)) Maximum wind speed.  Default units are\n",
    "       meters/second.\n",
    "     - *max_wind_radius* (ndarray(:)) Radius at which the maximum wind speed\n",
    "       occurs.  Default units are meters.\n",
    "     - *central_pressure* (ndarray(:)) Central pressure of storm.  Default\n",
    "       units are Pascals.\n",
    "     - *storm_radius* (ndarray(:)) Radius of storm, often defined as the last\n",
    "       closed iso-bar of pressure.  Default units are meters.\n",
    "     - *time_offset* (datetime.datetime) A date time that as an offset for the\n",
    "       simulation time.  This will default to the beginning of the first of the\n",
    "       year that the first time point is found in.\n",
    "     - *wind_speeds* (ndarray(:, :)) Wind speeds defined in every record, such\n",
    "       as 34kt, 50kt, 64kt, etc and their radii. Default units are meters/second\n",
    "       and meters.\n",
    "\n",
    "    :Initialization:\n",
    "     1. Read in existing file at *path*.\n",
    "     2. Construct an empty storm and supply the fields needed.  Note that these\n",
    "        fields must be converted to the appropriate units.\n",
    "\n",
    "    :Input:\n",
    "     - *path* (string) Path to file to be read in if requested.\n",
    "     - *file_format* (string) Format of file at path.  Default is \"hurdat\"\n",
    "     - *kwargs* (dict) Other key-word arguments are passed to the appropriate\n",
    "       read routine.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define supported formats and models - keys are function name related and\n",
    "    # values are the proper name and a citation or URL documenting the format\n",
    "    _supported_formats = {\"geoclaw\": [\"GeoClaw\", \"http://www.clawpack.org/storms\"],\n",
    "                          \"atcf\": [\"ATCF\", \"http://www.nrlmry.navy.mil/atcf_web/docs/database/new/database.html\"],\n",
    "                          \"hurdat\": [\"HURDAT\", \"http://www.aoml.noaa.gov/hrd/hurdat/Data_Storm.html\"],\n",
    "                          \"ibtracs\": [\"IBTrACS\", \"https://www.ncdc.noaa.gov/ibtracs/index.php?name=ib-v4-access\"],\n",
    "                          \"jma\": [\"JMA\", \"http://www.jma.go.jp/jma/jma-eng/jma-center/rsmc-hp-pub-eg/Besttracks/e_format_bst.html\"],\n",
    "                          \"imd\": [\"IMD\", \"http://www.rsmcnewdelhi.imd.gov.in/index.php\"],\n",
    "                          \"tcvitals\": [\"TC-Vitals\", \"http://www.emc.ncep.noaa.gov/mmb/data_processing/tcvitals_description.htm\"]}\n",
    "\n",
    "    def __init__(self, path=None, file_format=\"ATCF\", **kwargs):\n",
    "        r\"\"\"Storm Initiatlization Routine\n",
    "\n",
    "        See :class:`Storm` for more info.\n",
    "        \"\"\"\n",
    "\n",
    "        self.t = None\n",
    "        self.time_offset = None\n",
    "        self.eye_location = None\n",
    "        self.max_wind_speed = None\n",
    "        self.max_wind_radius = None\n",
    "        self.central_pressure = None\n",
    "        self.storm_radius = None\n",
    "        self.wind_speeds = None\n",
    "\n",
    "        # Storm descriptions - not all formats provide these\n",
    "        self.name = None\n",
    "        self.basin = None                   # Basin containing storm\n",
    "        self.ID = None                      # ID code - depends on format\n",
    "        self.classification = None          # Classification of storm (e.g. HU)\n",
    "        self.event = None                   # Event (e.g. landfall) - HURDAT\n",
    "\n",
    "        if path is not None:\n",
    "            self.read(path, file_format=file_format, **kwargs)\n",
    "\n",
    "    # ==========================================================================\n",
    "    #  Basic object support\n",
    "    def __str__(self):\n",
    "        r\"\"\"\"\"\"\n",
    "        output = \"Name: %s\" % self.name\n",
    "        output = \"\\n\".join((output, \"Dates: %s - %s\" % (self.t[0].isoformat(),\n",
    "                                                        self.t[-1].isoformat())\n",
    "                            ))\n",
    "        return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<{}.{} \"{}\" at {}>'.format(\n",
    "            self.__class__.__module__,\n",
    "            self.__class__.__name__,\n",
    "            self.__dict__.get('name', 'name not given'),\n",
    "            hex(id(self)))\n",
    "\n",
    "    # ==========================================================================\n",
    "    # Read Routines\n",
    "    def read(self, path=None, file_format=\"atcf\", **kwargs):\n",
    "        r\"\"\"Read in storm data from *path* with format *file_format*\n",
    "\n",
    "        :Input:\n",
    "         - *path* (string) Path to data file.\n",
    "         - *file_format* (string) Format of the data file.  See list of\n",
    "           supported formats for a list of valid strings.  Defaults to\n",
    "           \"hurdat\".\n",
    "         - *kwargs* (dict) Keyword dictionary for additional arguments that can\n",
    "           be passed down to the appropriate read functions.  Please refer to\n",
    "           the specific routine for a list of valid options.\n",
    "\n",
    "        :Raises:\n",
    "         - *ValueError* If the *file_format* requested does not match any of\n",
    "           the available supported formats a *ValueError* is raised.\n",
    "        \"\"\"\n",
    "\n",
    "        # If a path is not provided then we can try and find the relevant\n",
    "        # database and download it\n",
    "        if path is None:\n",
    "            data_str = (\"Currently automatic download of storm databases is \",\n",
    "                        \"not implemented.  Please refer to the URLs below for\",\n",
    "                        \"references as to where you can download storm data\",\n",
    "                        \"files:\",\n",
    "                        \" - ATCF - http://ftp.nhc.noaa.gov/atcf/archive/\",\n",
    "                        \" - HURDAT - http://www.aoml.noaa.gov/hrd/hurdat/Data_Storm.html\",\n",
    "                        \" - IBTrACS - https://www.ncdc.noaa.gov/ibtracs/index.php?name=ib-v4-access\",\n",
    "                        \" - JMA - http://www.jma.go.jp/jma/jma-eng/jma-center/rsmc-hp-pub-eg/besttrack.html\",\n",
    "                        \" - IMD - http://www.rsmcnewdelhi.imd.gov.in/index.php\",\n",
    "                        \" - TCVITALS - http://www.emc.ncep.noaa.gov/mmb/data_processing/tcvitals_description.htm\")\n",
    "            raise NotImplementedError(\"\\n\".join(data_str))\n",
    "\n",
    "        if file_format.lower() not in self._supported_formats.keys():\n",
    "            raise ValueError(\"File format %s not available.\" % file_format)\n",
    "\n",
    "        getattr(self, 'read_%s' % file_format.lower())(path, **kwargs)\n",
    "\n",
    "    def read_geoclaw(self, path, verbose=False):\n",
    "        r\"\"\"Read in a GeoClaw formatted storm file\n",
    "\n",
    "        GeoClaw storm files are read in by the Fortran code and are not meant\n",
    "        to be human readable.\n",
    "\n",
    "        :Input:\n",
    "         - *path* (string) Path to the file to be read.\n",
    "         - *verbose* (bool) Output more info regarding reading.\n",
    "        \"\"\"\n",
    "\n",
    "        with open(path, 'r') as data_file:\n",
    "            num_casts = int(data_file.readline())\n",
    "            self.time_offset = datetime.datetime.strptime(\n",
    "                                                      data_file.readline()[:19],\n",
    "                                                      '%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "        data = numpy.loadtxt(path, skiprows=3)\n",
    "        num_forecasts = data.shape[0]\n",
    "        self.eye_location = numpy.empty((2, num_forecasts))\n",
    "        assert(num_casts == num_forecasts)\n",
    "        self.t = [self.time_offset + datetime.timedelta(seconds=data[i, 0])\n",
    "                  for i in range(num_forecasts)]\n",
    "        self.eye_location[0, :] = data[:, 1]\n",
    "        self.eye_location[1, :] = data[:, 2]\n",
    "        self.max_wind_speed = data[:, 3]\n",
    "        self.max_wind_radius = data[:, 4]\n",
    "        self.central_pressure = data[:, 5]\n",
    "        self.storm_radius = data[:, 6]\n",
    "\n",
    "    def read_atcf(self, path, verbose=False):\n",
    "        r\"\"\"Read in a ATCF formatted storm file\n",
    "\n",
    "        ATCF format has storm stored individually so there is no support for\n",
    "        multiple storms in a particular file.\n",
    "\n",
    "        :Input:\n",
    "         - *path* (string) Path to the file to be read.\n",
    "         - *verbose* (bool) Output more info regarding reading.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import pandas as pd\n",
    "        except ImportError as e:\n",
    "            print(\"read_atcf currently requires pandas to work.\")\n",
    "            raise e\n",
    "\n",
    "        # See here for the ATCF format documentation:\n",
    "        #   https://www.nrlmry.navy.mil/atcf_web/docs/database/new/abdeck.txt\n",
    "        df = pd.read_csv(path, engine=\"python\", sep=\",+\", names=[\n",
    "                \"BASIN\", \"CY\", \"YYYYMMDDHH\", \"TECHNUM\", \"TECH\", \"TAU\",\n",
    "                \"LAT\", \"LON\", \"VMAX\", \"MSLP\", \"TY\",\n",
    "                \"RAD\", \"WINDCODE\", \"RAD1\", \"RAD2\", \"RAD3\", \"RAD4\",\n",
    "                \"POUTER\", \"ROUTER\", \"RMW\", \"GUSTS\", \"EYE\", \"SUBREGION\",\n",
    "                \"MAXSEAS\", \"INITIALS\", \"DIR\", \"SPEED\", \"STORMNAME\", \"DEPTH\",\n",
    "                \"SEAS\", \"SEASCODE\", \"SEAS1\", \"SEAS2\", \"SEAS3\", \"SEAS4\",\n",
    "                \"USERDEFINE1\", \"userdata1\",\n",
    "                \"USERDEFINE2\", \"userdata2\",\n",
    "                \"USERDEFINE3\", \"userdata3\",\n",
    "                \"USERDEFINE4\", \"userdata4\",\n",
    "                \"USERDEFINE5\", \"userdata5\",\n",
    "            ],\n",
    "            converters={\n",
    "                \"YYYYMMDDHH\": lambda d: datetime.datetime(\n",
    "                    int(d[1:5]), int(d[5:7]), int(d[7:9]), int(d[9:11])),\n",
    "                \"TAU\": lambda d: datetime.timedelta(hours=int(d)),\n",
    "                \"LAT\": lambda d: (-.1 if d[-1] == \"S\" else .1) * int(d.strip(\"NS \")),\n",
    "                \"LON\": lambda d: (-.1 if d[-1] == \"W\" else .1) * int(d.strip(\"WE \")),\n",
    "            },\n",
    "            dtype={\n",
    "                \"BASIN\": str,\n",
    "                \"CY\": int,\n",
    "                \"VMAX\": float,\n",
    "                \"MSLP\": float,\n",
    "                \"TY\": str,\n",
    "                \"RAD\": float,\n",
    "                \"RAD1\": float,\n",
    "                \"RAD2\": float,\n",
    "                \"RAD3\": float,\n",
    "                \"RAD4\": float,\n",
    "                \"ROUTER\": float,\n",
    "                \"RMW\": float,\n",
    "            })\n",
    "\n",
    "        # Grab data regarding basin and cyclone number from first row\n",
    "        self.basin = ATCF_basins[df[\"BASIN\"][0]]\n",
    "        self.ID = df[\"CY\"][0]\n",
    "\n",
    "        # Take forecast period TAU into consideration\n",
    "        df['DATE'] = df[\"YYYYMMDDHH\"] + df[\"TAU\"]\n",
    "        df = df[[\"DATE\", \"TAU\", \"TY\", \"LAT\", \"LON\", \"VMAX\", \"MSLP\",\n",
    "                 \"ROUTER\", \"RMW\", \"RAD\", \"RAD1\", \"RAD2\", \"RAD3\", \"RAD4\",]]\n",
    "        df = df.sort_values(by=[\"DATE\", \"TAU\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "        # For each DATE, choose best (smallest TAU) available data\n",
    "        for c in [\"LAT\", \"LON\", \"VMAX\", \"MSLP\", \"ROUTER\", \"RMW\",\n",
    "                  \"RAD\", \"RAD1\", \"RAD2\", \"RAD3\", \"RAD4\"]:\n",
    "            df[c] = df[c].where(df[c] != 0, numpy.nan)  # value 0 means NaN\n",
    "            df[c] = df.groupby(\"DATE\")[c].fillna(method=\"bfill\")\n",
    "        df = df.groupby(\"DATE\").first()\n",
    "\n",
    "        # Wind profile (occasionally missing for older ATCF storms)\n",
    "        # Wind speeds and their radii\n",
    "        df[\"RAD_MEAN\"] = df[[\"RAD1\", \"RAD2\", \"RAD3\", \"RAD4\"]].mean(axis=1, skipna=True)\n",
    "        df = df.drop([\"TAU\", \"RAD1\", \"RAD2\", \"RAD3\", \"RAD4\"], axis=1)\n",
    "        df = df.dropna(how=\"any\", subset=[\"LAT\", \"LON\"])\n",
    "\n",
    "        # Create time\n",
    "        self.t = list(df.index.to_pydatetime())\n",
    "\n",
    "        # Classification, note that this is not the category of the storm\n",
    "        self.classification = df[\"TY\"].to_numpy()\n",
    "\n",
    "        # Eye location - longitude/latitude order\n",
    "        self.eye_location = df[[\"LON\", \"LAT\"]].to_numpy()\n",
    "\n",
    "        # Convert to correct units:\n",
    "        #  max_wind_speed - Convert knots to m/s - 0.51444444\n",
    "        #  max_wind_radius  - convert from nm to m - 1.8520000031807990 * 1000.0\n",
    "        #  central_pressure - convert from mbar to Pa - 100.0\n",
    "        #  Radius of last isobar contour - convert from nm to m - 1.852000003180799d0 * 1000.0\n",
    "        self.max_wind_speed = units.convert(df[\"VMAX\"].to_numpy(), 'knots', 'm/s')\n",
    "        self.central_pressure = units.convert(df[\"MSLP\"].to_numpy(), 'mbar', 'Pa')\n",
    "        self.max_wind_radius = units.convert(df[\"RMW\"].to_numpy(), 'nmi', 'm')\n",
    "        self.storm_radius = units.convert(df[\"ROUTER\"].to_numpy(), 'nmi', 'm')\n",
    "        self.wind_speeds = df[[\"RAD\",\"RAD_MEAN\"]].to_numpy()\n",
    "        self.wind_speeds[:,0] = units.convert(self.wind_speeds[:,0], 'knots', 'm/s')\n",
    "        self.wind_speeds[:,1] = units.convert(self.wind_speeds[:,1], 'nmi', 'm')\n",
    "\n",
    "        # Set NaNs to -1 to mark them as missing\n",
    "        for ar in [self.max_wind_speed, self.central_pressure,\n",
    "                   self.max_wind_radius, self.storm_radius, self.wind_speeds]:\n",
    "            ar[numpy.isnan(ar)] = -1.\n",
    "\n",
    "        if self.max_wind_speed.min() == -1:\n",
    "            warnings.warn('Some timesteps have missing max wind speed. These will not be written'\n",
    "                          ' out to geoclaw format.')\n",
    "        if self.central_pressure.min() == -1:\n",
    "            warnings.warn('Some timesteps have missing central pressure. These will not be written'\n",
    "                          ' out to geoclaw format.')\n",
    "\n",
    "    def read_hurdat(self, path, verbose=False):\n",
    "        r\"\"\"Read in HURDAT formatted storm file\n",
    "\n",
    "        This is the current version of HURDAT data available (HURDAT 2).  Note\n",
    "        that this assumes there is only one storm in the file (includes the\n",
    "        header information though).  Future features will be added that will allow for\n",
    "        a file to be read with multiple storms defined.\n",
    "\n",
    "        For more details on the HURDAT format and getting data see\n",
    "\n",
    "        http://www.aoml.noaa.gov/hrd/hurdat/Data_Storm.html\n",
    "\n",
    "        :Input:\n",
    "         - *path* (string) Path to the file to be read.\n",
    "         - *verbose* (bool) Output more info regarding reading.\n",
    "\n",
    "        :Raises:\n",
    "         - *ValueError* If the method cannot find the name/year matching the\n",
    "           storm or they are not provided when *single_storm == False* then a\n",
    "           value error is risen.\n",
    "        \"\"\"\n",
    "\n",
    "        with open(path, 'r') as hurdat_file:\n",
    "            # Extract header\n",
    "            data = [value.strip() for value in\n",
    "                    hurdat_file.readline().split(',')]\n",
    "            self.basin = data[0][:2]\n",
    "            self.name = data[1]\n",
    "            self.ID = data[2]\n",
    "\n",
    "            # Store rest of data\n",
    "            data_block = hurdat_file.readlines()\n",
    "\n",
    "        num_lines = len(data_block)\n",
    "\n",
    "        # Parse data block\n",
    "        self.t = []\n",
    "        self.event = numpy.empty(num_lines, dtype=str)\n",
    "        self.classification = numpy.empty(num_lines, dtype=str)\n",
    "        self.eye_location = numpy.empty((num_lines, 2))\n",
    "        self.max_wind_speed = numpy.empty(num_lines)\n",
    "        self.central_pressure = numpy.empty(num_lines)\n",
    "        self.max_wind_radius = numpy.empty(num_lines)\n",
    "        self.storm_radius = numpy.empty(num_lines)\n",
    "\n",
    "        for (i, line) in enumerate(data_block):\n",
    "            if len(line) == 0:\n",
    "                break\n",
    "            data = [value.strip() for value in line.split(\",\")]\n",
    "\n",
    "            # Create time\n",
    "            self.t.append(datetime.datetime(int(data[0][:4]),\n",
    "                                            int(data[0][4:6]),\n",
    "                                            int(data[0][6:8]),\n",
    "                                            int(data[1][:2]),\n",
    "                                            int(data[1][2:])))\n",
    "\n",
    "            # If an event is occuring record it.  If landfall then use as an\n",
    "            # offset.   Note that if there are multiple landfalls the last one\n",
    "            # is used as the offset\n",
    "            if len(data[2].strip()) > 0:\n",
    "                self.event[i] = data[2].strip()\n",
    "                if self.event[i].upper() == \"L\":\n",
    "                    self.time_offset = self.t[i]\n",
    "\n",
    "            # Classification, note that this is not the category of the storm\n",
    "            self.classification[i] = data[3]\n",
    "\n",
    "            # Parse eye location\n",
    "            if data[4][-1] == \"N\":\n",
    "                self.eye_location[i, 1] = float(data[4][0:-1])\n",
    "            else:\n",
    "                self.eye_location[i, 1] = -float(data[4][0:-1])\n",
    "            if data[5][-1] == \"E\":\n",
    "                self.eye_location[i, 0] = float(data[5][0:-1])\n",
    "            else:\n",
    "                self.eye_location[i, 0] = -float(data[5][0:-1])\n",
    "\n",
    "            # Intensity information - radii are not included directly in this\n",
    "            # format and instead radii of winds above a threshold are included\n",
    "            self.max_wind_speed[i] = units.convert(float(data[6]), 'knots', 'm/s')\n",
    "            self.central_pressure[i] = units.convert(float(data[7]), 'mbar', 'Pa')\n",
    "            warnings.warn(missing_data_warning_str)\n",
    "            self.max_wind_radius[i] = -1\n",
    "            self.storm_radius[i] = -1\n",
    "\n",
    "    def read_ibtracs(self, path, sid=None, storm_name=None, year=None, start_date=None,\n",
    "                     agency_pref = ['wmo',\n",
    "                                   'usa',\n",
    "                                   'tokyo',\n",
    "                                   'newdelhi',\n",
    "                                   'reunion',\n",
    "                                   'bom',\n",
    "                                   'nadi',\n",
    "                                   'wellington',\n",
    "                                   'cma',\n",
    "                                   'hko',\n",
    "                                   'ds824',\n",
    "                                   'td9636',\n",
    "                                   'td9635',\n",
    "                                   'neumann',\n",
    "                                   'mlc']):\n",
    "        r\"\"\"Read in IBTrACS formatted storm file\n",
    "\n",
    "        This reads in the netcdf-formatted IBTrACS v4 data. You must either pass\n",
    "        the *sid* of the storm (a unique identifier supplied by IBTrACS) OR\n",
    "        *storm_name* and *year*. The latter will not be unique for unnamed storms,\n",
    "        so you may optionally pass *start_date* as well. The `wmo_\\*` variable is\n",
    "        used when non-missing, with missing values filled in by the corresponding\n",
    "        variable of the agency specified in `wmo_agency` and/or `usa_agency`. If\n",
    "        still missing, the other agencies are checked in order of *agency_pref* to\n",
    "        see if any more non-missing values are available.\n",
    "\n",
    "        :Input:\n",
    "         - *path* (string) Path to the file to be read.\n",
    "         - *sid* (string, optional) IBTrACS-supplied unique track identifier.\n",
    "             Either *sid* OR *storm_name* and *year* must not be None.\n",
    "         - *storm_name* (string, optional) name of storm of interest\n",
    "             (NAME field in IBTrACS). Either *sid* OR *storm_name* and\n",
    "             *year* must not be None.\n",
    "         - *year* (int, optional) year of storm of interest.\n",
    "             Either *sid* OR *storm_name* and *year* must not be None.\n",
    "         - *start_date* (:py:class:`datetime.datetime`, optional) If storm is not\n",
    "             named, will find closest unnamed storm to this start date. Only\n",
    "             used for unnamed storms when specifying *storm_name* and *year*\n",
    "             does not uniquely identify storm.\n",
    "         - *agency_pref* (list, optional) Preference order to use if `wmo_\\*` variable\n",
    "             is missing and `wmo_agency` and `usa_agency` are also missing.\n",
    "\n",
    "        :Raises:\n",
    "         - *ValueError* If the method cannot find the matching storm then a\n",
    "             value error is risen.\n",
    "        \"\"\"\n",
    "\n",
    "        # imports that you don't need for other read functions\n",
    "        try:\n",
    "            import xarray as xr\n",
    "        except ImportError as e:\n",
    "            print(\"IBTrACS currently requires xarray to work.\")\n",
    "            raise e\n",
    "\n",
    "        # only allow one method for specifying storms\n",
    "        if (sid is not None) and ((storm_name is not None) or (year is not None)):\n",
    "            raise ValueError('Cannot specify both *sid* and *storm_name* or *year*.')\n",
    "\n",
    "        with xr.open_dataset(path) as ds:\n",
    "\n",
    "            # match on sid\n",
    "            if sid is not None:\n",
    "                match = ds.sid == sid.encode()\n",
    "            # or match on storm_name and year\n",
    "            else:\n",
    "                storm_name = storm_name.upper()\n",
    "                # in case storm is unnamed\n",
    "                if storm_name.upper() in ['UNNAMED','NO-NAME']:\n",
    "                    storm_name = 'NOT_NAMED'\n",
    "                storm_match = (ds.name == storm_name.encode())\n",
    "                year_match = (ds.time.dt.year == year).any(dim='date_time')\n",
    "                match = storm_match & year_match\n",
    "            ds = ds.sel(storm=match).squeeze()\n",
    "\n",
    "            # occurs if we have 0 or >1 matching storms\n",
    "            if 'storm' in ds.dims.keys():\n",
    "                if ds.storm.shape[0] == 0:\n",
    "                    raise ValueError('Storm/year not found in provided file')\n",
    "                else:\n",
    "                    # see if a date was provided for multiple unnamed storms\n",
    "                    assert start_date is not None, ValueError('Multiple storms identified and no start_date specified.')\n",
    "\n",
    "                    start_times = ds.time.isel(date_time=0)\n",
    "                    start_date = numpy.datetime64(start_date)\n",
    "\n",
    "                    # find storm with start date closest to provided\n",
    "                    storm_ix = abs(start_times - start_date).argmin()\n",
    "                    ds = ds.isel(storm=storm_ix).squeeze()\n",
    "                    assert 'storm' not in ds.dims.keys()\n",
    "\n",
    "            # cut down dataset to only non-null times\n",
    "            valid_t = ds.time.notnull()\n",
    "            if valid_t.sum() == 0:\n",
    "                raise ValueError('No valid wind speeds found for this storm.')\n",
    "            ds = ds.sel(date_time=valid_t)\n",
    "\n",
    "\n",
    "            # list of the agencies that correspond to 'usa_*' variables\n",
    "            usa_agencies = [b'atcf', b'hurdat_atl', b'hurdat_epa', b'jtwc_ep',\n",
    "                           b'nhc_working_bt', b'tcvightals', b'tcvitals']\n",
    "\n",
    "\n",
    "            ## Create mapping from wmo_ or usa_agency\n",
    "            ## to the appropriate variable\n",
    "            agency_map = {b'':agency_pref.index('wmo')}\n",
    "            # account for multiple usa agencies\n",
    "            for a in usa_agencies:\n",
    "                agency_map[a] = agency_pref.index('usa')\n",
    "            # map all other agencies to themselves\n",
    "            for i in [a for a in agency_pref if a not in ['wmo','usa']]:\n",
    "                agency_map[i.encode('utf-8')] = agency_pref.index(i)\n",
    "\n",
    "            # fill in usa as provider if usa_agency is\n",
    "            # non-null when wmo_agency is null\n",
    "            provider = ds.wmo_agency.where(ds.wmo_agency!=b'',ds.usa_agency)\n",
    "\n",
    "            # get index into from agency that is wmo_provider\n",
    "            def map_val_to_ix(a):\n",
    "                func = lambda x: agency_map[x]\n",
    "                return xr.apply_ufunc(func,a, vectorize=True)\n",
    "            pref_agency_ix=map_val_to_ix(provider)\n",
    "\n",
    "            ## GET MAX WIND SPEED and PRES\n",
    "            pref_vals = {}\n",
    "            for v in ['wind','pres']:\n",
    "                all_vals = ds[['{}_{}'.format(i,v) for i in agency_pref]].to_array(dim='agency')\n",
    "\n",
    "                # get wmo value\n",
    "                val_pref = ds['wmo_'+v]\n",
    "\n",
    "                # fill this value in as a second-best\n",
    "                pref_2 = all_vals.isel(agency=pref_agency_ix)\n",
    "                val_pref = val_pref.fillna(pref_2)\n",
    "\n",
    "                # now use the agency_pref order to fill in\n",
    "                # any remaining values as third best\n",
    "                best_ix = all_vals.notnull().argmax(dim='agency')\n",
    "                pref_3 = all_vals.isel(agency=best_ix)\n",
    "                val_pref = val_pref.fillna(pref_3)\n",
    "\n",
    "                # add to dict\n",
    "                pref_vals[v] = val_pref\n",
    "\n",
    "\n",
    "            ## THESE CANNOT BE MISSING SO DROP\n",
    "            ## IF EITHER MISSING\n",
    "            valid = pref_vals['wind'].notnull() & pref_vals['pres'].notnull()\n",
    "            if not valid.any():\n",
    "                raise NoDataError(missing_necessary_data_warning_str)\n",
    "            ds = ds.sel(date_time=valid)\n",
    "            for i in ['wind','pres']:\n",
    "                pref_vals[i] = pref_vals[i].sel(date_time=valid)\n",
    "\n",
    "\n",
    "            ## GET RMW and ROCI\n",
    "            ## (these can be missing)\n",
    "            for r in ['rmw','roci']:\n",
    "                order = ['{}_{}'.format(i,r) for i in agency_pref if\n",
    "                                 '{}_{}'.format(i,r) in ds.data_vars.keys()]\n",
    "                vals = ds[order].to_array(dim='agency')\n",
    "                best_ix = vals.notnull().argmax(dim='agency')\n",
    "                val_pref = vals.isel(agency=best_ix)\n",
    "                pref_vals[r] = val_pref\n",
    "\n",
    "\n",
    "            ## CONVERT TO GEOCLAW FORMAT\n",
    "\n",
    "            # assign basin to be the basin where track originates\n",
    "            # in case track moves across basins\n",
    "            self.basin = ds.basin.values[0].astype(str)\n",
    "            self.name = ds.name.astype(str).item()\n",
    "            self.ID = ds.sid.astype(str).item()\n",
    "\n",
    "            # convert datetime64 to datetime.datetime\n",
    "            self.t = []\n",
    "            for d in ds.time:\n",
    "                t = d.dt\n",
    "                self.t.append(datetime.datetime(t.year,t.month,t.day,t.hour,t.minute,t.second))\n",
    "\n",
    "            ## events\n",
    "            self.event = ds.usa_record.values.astype(str)\n",
    "\n",
    "            ## time offset\n",
    "            if (self.event=='L').any():\n",
    "                # if landfall, use last landfall\n",
    "                self.time_offset = numpy.array(self.t)[self.event=='L'][-1]\n",
    "            else:\n",
    "                #if no landfall, use last time of storm\n",
    "                self.time_offset = self.t[-1]\n",
    "\n",
    "            # Classification, note that this is not the category of the storm\n",
    "            self.classification = ds.usa_status.values\n",
    "            self.eye_location = numpy.array([ds.lon,ds.lat]).T\n",
    "\n",
    "            # Intensity information - for now, including only common, basic intensity\n",
    "            # info.\n",
    "            # TODO: add more detailed info for storms that have it\n",
    "            self.max_wind_speed = units.convert(pref_vals['wind'],'knots','m/s').where(pref_vals['wind'].notnull(),-1).values\n",
    "            self.central_pressure = units.convert(pref_vals['pres'],'mbar','Pa').where(pref_vals['pres'].notnull(),-1).values\n",
    "            self.max_wind_radius = units.convert(pref_vals['rmw'],'nmi','m').where(pref_vals['rmw'].notnull(),-1).values\n",
    "            self.storm_radius = units.convert(pref_vals['roci'],'nmi','m').where(pref_vals['roci'].notnull(),-1).values\n",
    "\n",
    "            # warn if you have missing vals for RMW or ROCI\n",
    "            if (self.max_wind_radius.max()) == -1 or (self.storm_radius.max() == -1):\n",
    "                warnings.warn(missing_data_warning_str)\n",
    "\n",
    "\n",
    "    def read_jma(self, path, verbose=False):\n",
    "        r\"\"\"Read in JMA formatted storm file\n",
    "\n",
    "        Note that only files that contain one storm are currently supported.\n",
    "\n",
    "        For more details on the JMA format and getting data see\n",
    "\n",
    "        http://www.jma.go.jp/jma/jma-eng/jma-center/rsmc-hp-pub-eg/Besttracks/e_format_bst.html\n",
    "\n",
    "        :Input:\n",
    "         - *path* (string) Path to the file to be read.\n",
    "         - *verbose* (bool) Output more info regarding reading.\n",
    "\n",
    "        :Raises:\n",
    "         - *ValueError* If the method cannot find the name/year matching the\n",
    "           storm or they are not provided when *single_storm == False* then a\n",
    "           value error is risen.\n",
    "        \"\"\"\n",
    "\n",
    "        data_block = []\n",
    "        with open(path, 'r') as JMA_file:\n",
    "            # Extract header\n",
    "            data = JMA_file.readline()\n",
    "            self.ID = data[6:10]\n",
    "            num_lines = int(data[12:14])\n",
    "            self.name = data[30:51].strip()\n",
    "\n",
    "            data_block = JMA_file.readlines()\n",
    "        assert(num_lines == len(data_block))\n",
    "\n",
    "        # Parse data block\n",
    "        self.t = []\n",
    "        self.event = numpy.empty(num_lines, dtype=str)\n",
    "        self.classification = numpy.empty(num_lines, dtype=str)\n",
    "        self.eye_location = numpy.empty((num_lines, 2))\n",
    "        self.max_wind_speed = numpy.empty(num_lines)\n",
    "        self.central_pressure = numpy.empty(num_lines)\n",
    "        self.max_wind_radius = numpy.empty(num_lines)\n",
    "        self.storm_radius = numpy.empty(num_lines)\n",
    "        for (i, line) in enumerate(data_block):\n",
    "            if len(line) == 0:\n",
    "                break\n",
    "            data = [value.strip() for value in line.split()]\n",
    "\n",
    "            # Create time\n",
    "            self.t.append(datetime.datetime(int(data[0][:2]),\n",
    "                                            int(data[0][2:4]),\n",
    "                                            int(data[0][4:6]),\n",
    "                                            int(data[0][6:])))\n",
    "\n",
    "            # Classification, note that this is not the category of the storm\n",
    "            self.classification[i] = int(data[1])\n",
    "\n",
    "            # Parse eye location - Always N latitude and E longitude\n",
    "            self.eye_location[i, 0] = float(data[4]) / 10.0\n",
    "            self.eye_location[i, 1] = float(data[3]) / 10.0\n",
    "\n",
    "            # Intensity information - current the radii are not directly given\n",
    "            # Available data includes max/min of radius of winds of 50 and\n",
    "            # 30 kts instead\n",
    "            self.central_pressure[i] = units.convert(float(data[5]), 'hPa', 'Pa')\n",
    "            self.max_wind_speed[i] = units.convert(float(data[6]), 'knots', 'm/s')\n",
    "            warnings.warn(missing_data_warning_str)\n",
    "            self.max_wind_radius[i] = -1\n",
    "            self.storm_radius[i] = -1\n",
    "\n",
    "\n",
    "    def read_imd(self, path, verbose=False):\n",
    "        r\"\"\"Extract relevant hurricane data from IMD file\n",
    "            and update storm fields with proper values.\n",
    "\n",
    "        :Input:\n",
    "         - *path* (string) Path to the file to be read.\n",
    "\n",
    "        Return ValueError if format incorrect or if file not IMD.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError((\"Reading in IMD files is not \",\n",
    "                                   \"implemented yet but is planned for a \",\n",
    "                                   \"future release.\"))\n",
    "\n",
    "\n",
    "    def read_tcvitals(self, path, verbose=False):\n",
    "        r\"\"\"Extract relevant hurricane data from TCVITALS file\n",
    "            and update storm fields with proper values.\n",
    "\n",
    "        :Input:\n",
    "         - *path* (string) Path to the file to be read.\n",
    "         - *verbose* (bool) Output more info regarding reading.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # read in TCVitals_file\n",
    "        data_block = []\n",
    "        with open(path, 'r') as TCVitals_file:\n",
    "            data = TCVitals_file.readlines()\n",
    "            for line in data:\n",
    "                line = line.split()\n",
    "                line = [value.strip() for value in line]\n",
    "                data_block.append(line)\n",
    "        num_lines = len(data_block)\n",
    "\n",
    "        # Parse data block - convert to correct units\n",
    "        # Conversions:\n",
    "        #  max_wind_radius  - convert from km to m - 1000.0\n",
    "        #  Central_pressure - convert from mbar to Pa - 100.0\n",
    "        #  Radius of last isobar contour - convert from km to m - 1000.0\n",
    "        self.t = []\n",
    "        self.classification = numpy.empty(num_lines, dtype=str)\n",
    "        self.eye_location = numpy.empty((num_lines, 2))\n",
    "        self.max_wind_speed = numpy.empty(num_lines)\n",
    "        self.central_pressure = numpy.empty(num_lines)\n",
    "        self.max_wind_radius = numpy.empty(num_lines)\n",
    "        self.storm_radius = numpy.empty(num_lines)\n",
    "\n",
    "        for (i, data) in enumerate(data_block):\n",
    "            # End at an empty lines - skips lines at the bottom of a file\n",
    "            if len(data) == 0:\n",
    "                break\n",
    "\n",
    "            # Grab data regarding basin and cyclone number if we are starting\n",
    "            if i == 0:\n",
    "                self.basin = TCVitals_Basins[data[1][2:]]\n",
    "                self.ID = int(data[1][:2])\n",
    "\n",
    "            # Create time\n",
    "            self.t.append(datetime.datetime(int(data[3][0:4]),\n",
    "                                            int(data[3][4:6]),\n",
    "                                            int(data[3][6:]),\n",
    "                                            int(data[4][:2])))\n",
    "\n",
    "            # Parse eye location - longitude/latitude order\n",
    "            if data[5][-1] == 'N':\n",
    "                self.eye_location[i, 1] = float(data[5][0:-1])/10.0\n",
    "            else:\n",
    "                self.eye_location[i, 1] = -float(data[5][0:-1])/10.0\n",
    "            if data[6][-1] == \"E\":\n",
    "                self.eye_location[i, 0] = float(data[6][0:-1])/10.0\n",
    "            else:\n",
    "                self.eye_location[i, 0] = -float(data[6][0:-1])/10.0\n",
    "\n",
    "            # Intensity Information\n",
    "            self.max_wind_speed[i] = float(data[12])\n",
    "            self.central_pressure[i] = units.convert(float(data[9]), 'mbar', 'Pa')\n",
    "            self.max_wind_radius[i] = units.convert(float(data[13]), 'km', 'm')\n",
    "            self.storm_radius[i] = units.convert(float(data[11]), 'km', 'm')\n",
    "\n",
    "\n",
    "    # =========================================================================\n",
    "    # Write Routines\n",
    "    def write(self, path, file_format=\"geoclaw\", **kwargs):\n",
    "        r\"\"\"Write out the storm data to *path* in format *file_format*\n",
    "\n",
    "        :Input:\n",
    "         - *path* (string) Path to data file.\n",
    "         - *file_format* (string) Format of the data file.  See list of\n",
    "           supported formats for a list of valid strings.  Defaults to\n",
    "           \"geoclaw\".\n",
    "         - *kwargs* (dict) Keyword dictionary for additional arguments that can\n",
    "           be passed down to the appropriate write functions.  Please refer to\n",
    "           the specific routine for a list of valid options.\n",
    "\n",
    "        :Raises:\n",
    "         - *ValueError* If the *file_format* requested does not match any of\n",
    "           the available supported formats a *ValueError* is raised.\n",
    "        \"\"\"\n",
    "\n",
    "        if file_format.lower() not in self._supported_formats.keys():\n",
    "            raise ValueError(\"File format %s not available.\" % file_format)\n",
    "\n",
    "        getattr(self, 'write_%s' % file_format.lower())(path, **kwargs)\n",
    "\n",
    "    def write_geoclaw(self, path, verbose=False, max_wind_radius_fill=None,\n",
    "                            storm_radius_fill=None):\n",
    "        r\"\"\"Write out a GeoClaw formatted storm file\n",
    "\n",
    "        GeoClaw storm files are read in by the GeoClaw Fortran code.\n",
    "\n",
    "        :Input:\n",
    "         - *path* (string) Path to the file to be written.\n",
    "         - *verbose* (bool) Print out additional information when writing.\n",
    "         - *max_wind_radius_fill* (func) Function that can be used to fill in\n",
    "           missing data for `max_wind_radius` values.  This defaults to simply\n",
    "           setting the value to -1.  The function signature should be\n",
    "           `max_wind_radius(t, storm)` where t is the time of the forecast and\n",
    "           `storm` is the storm object.  Note that if this or `storm_radius`\n",
    "           field remains -1 that this data line will be assumed to be redundant\n",
    "           and not be written out.\n",
    "         - *storm_radius_fill* (func) Function that can be used to fill in\n",
    "           missing data for `storm_radius` values.  This defaults to simply\n",
    "           setting the value to -1.  The function signature should be\n",
    "           `storm_radius(t, storm)` where t is the time of the forecast and\n",
    "           `storm` is the storm object.  Note that if this or `max_wind_radius`\n",
    "           field remains -1 that this data line will be assumed to be redundant\n",
    "           and not be written\n",
    "        \"\"\"\n",
    "\n",
    "        if max_wind_radius_fill is None:\n",
    "            max_wind_radius_fill = lambda t, storm: -1\n",
    "        if storm_radius_fill is None:\n",
    "            storm_radius_fill = lambda t, storm: -1\n",
    "\n",
    "        # Create list for output\n",
    "        # Leave this first line blank as we need to count the actual valid lines\n",
    "        # that will be left in the file below\n",
    "        num_casts = 0\n",
    "        data_string = [\"\"]\n",
    "        if self.time_offset is None:\n",
    "            # Use the first time in sequence if not provided\n",
    "            self.time_offset = self.t[0]\n",
    "        data_string.append(\"%s\\n\\n\" % self.time_offset.isoformat())\n",
    "        for n in range(len(self.t)):\n",
    "            # Remove duplicate times\n",
    "            if n > 0:\n",
    "                if self.t[n] == self.t[n - 1]:\n",
    "                    continue\n",
    "\n",
    "            format_string = (\"{:19,.8e} \" * 7)[:-1] + \"\\n\"\n",
    "            data = []\n",
    "            data.append((self.t[n] - self.time_offset).total_seconds())\n",
    "            data.append(self.eye_location[n, 0])\n",
    "            data.append(self.eye_location[n, 1])\n",
    "\n",
    "            if self.max_wind_speed[n] == -1:\n",
    "                continue\n",
    "            data.append(self.max_wind_speed[n])\n",
    "\n",
    "            # Allow custom function to set max wind radius if not\n",
    "            # available\n",
    "            if self.max_wind_radius[n] == -1:\n",
    "                new_wind_radius = max_wind_radius_fill(self.t[n], self)\n",
    "                if new_wind_radius == -1:\n",
    "                    continue\n",
    "                else:\n",
    "                    data.append(new_wind_radius)\n",
    "            else:\n",
    "                data.append(self.max_wind_radius[n])\n",
    "\n",
    "            if self.central_pressure[n] == -1:\n",
    "                continue\n",
    "            data.append(self.central_pressure[n])\n",
    "\n",
    "            # Allow custom function to set storm radius if not available\n",
    "            if self.storm_radius[n] == -1:\n",
    "                new_storm_radius = storm_radius_fill(self.t[n], self)\n",
    "                if new_storm_radius == -1:\n",
    "                    continue\n",
    "                else:\n",
    "                    data.append(new_storm_radius)\n",
    "            else:\n",
    "                data.append(self.storm_radius[n])\n",
    "\n",
    "            data_string.append(format_string.format(*data))\n",
    "            num_casts += 1\n",
    "\n",
    "\n",
    "        # Write to actual file now that we know exactly how many lines it will\n",
    "        # contain\n",
    "        try:\n",
    "            # Update number of forecasts here\n",
    "            data_string[0] = \"%s\\n\" % num_casts\n",
    "            with open(path, \"w\") as data_file:\n",
    "                for data_line in data_string:\n",
    "                    data_file.write(data_line)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Remove possibly partially generated file if not successful\n",
    "            if os.path.exists(path):\n",
    "                os.remove(path)\n",
    "            raise e\n",
    "\n",
    "    def write_atcf(self, path, verbose=False):\n",
    "        r\"\"\"Write out a ATCF formatted storm file\n",
    "\n",
    "        :Input:\n",
    "         - *path* (string) Path to the file to be written.\n",
    "         - *verbose* (bool) Print out additional information when writing.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError((\"Writing out ATCF files is not implemented \",\n",
    "                                   \"yet but is planned for a future release.\"))\n",
    "        try:\n",
    "            with open(path, 'w') as data_file:\n",
    "                for n in range(len(self.t)):\n",
    "                    data_file.write(\"\".join((\", \" * 2,\n",
    "                                         \"%s\" % seconds2date(self.t[n]),\n",
    "                                         \", \" * 4,\n",
    "                                         \"%s\" % (int(self.eye_location[n, 0] *\n",
    "                                                     10.0)),\n",
    "                                         \", \",\n",
    "                                         \"%s\" % (int(self.eye_location[n, 1] *\n",
    "                                                     10.0)),\n",
    "                                         \", \",\n",
    "                                         \"%s\" % self.max_wind_speed[n],\n",
    "                                         \", \",\n",
    "                                         \"%s\" % self.central_pressure[n],\n",
    "                                         \", \",\n",
    "                                         \", \" * 8,\n",
    "                                         \"%s\" % self.storm_radius[n],\n",
    "                                         \", \",\n",
    "                                         \"%s\" % self.max_wind_radius[n],\n",
    "                                         \", \" * 10,\n",
    "                                         \"\\n\")))\n",
    "        except Exception as e:\n",
    "            # Remove possiblly partially generated file if not successful\n",
    "            if os.path.exists(path):\n",
    "                os.remove(path)\n",
    "            raise e\n",
    "\n",
    "    def write_hurdat(self, path, verbose=False):\n",
    "        r\"\"\"Write out a HURDAT formatted storm file\n",
    "\n",
    "        :Input:\n",
    "         - *path* (string) Path to the file to be written.\n",
    "         - *verbose* (bool) Print out additional information when writing.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError((\"Writing out hurdat files is not \",\n",
    "                                   \"implemented yet but is planned for a \",\n",
    "                                   \"future release.\"))\n",
    "        try:\n",
    "            with open(path, 'w') as data_file:\n",
    "                data_file.write('%s %s %s' % (\"Date\", \"Hurricane Name\",\n",
    "                                              \"Indicator\"))\n",
    "                for n in range(self.t.shape[0]):\n",
    "\n",
    "                    latitude = float(self.eye_location[n, 0])\n",
    "                    longitude = float(self.eye_location[n, 1])\n",
    "\n",
    "                    # Convert latitude to proper Hurdat format e.g 12.0N\n",
    "                    if latitude > 0:\n",
    "                        latitude = str(numpy.abs(latitude)) + 'N'\n",
    "                    else:\n",
    "                        latitude = str(numpy.abs(latitude)) + 'S'\n",
    "\n",
    "                    # Convert longitude to proper Hurdat format e.g 12.0W\n",
    "                    if longitude > 0:\n",
    "                        longitude = str(numpy.abs(longitude)) + 'E'\n",
    "                    else:\n",
    "                        longitude = str(numpy.abs(longitude)) + 'W'\n",
    "\n",
    "                    data_file.write(\"\".join((\"%s\" % self.seconds2date(\n",
    "                                                              self.t[n])[0:-2],\n",
    "                                         \"%s00\" % self.seconds2date(\n",
    "                                                              self.t[n])[-2:],\n",
    "                                         \", \" * 3,\n",
    "                                         \"%s\" % (latitude),\n",
    "                                         \", \",\n",
    "                                         \"%s\" % (longitude),\n",
    "                                         \", \",\n",
    "                                         \"%s\" % self.max_wind_speed[n],\n",
    "                                         \", \",\n",
    "                                         \"%s\" % self.central_pressure[n],\n",
    "                                         \", \",\n",
    "                                         \"%s\" % self.storm_radius[n],\n",
    "                                         \", \",\n",
    "                                         \"%s\" % self.max_wind_radius[n],\n",
    "                                         \", \" * 10,\n",
    "                                         \"\\n\")))\n",
    "        except Exception as e:\n",
    "            # Remove possiblly partially generated file if not successful\n",
    "            if os.path.exists(path):\n",
    "                os.remove(path)\n",
    "            raise e\n",
    "\n",
    "    def write_jma(self, path, verbose=False):\n",
    "        r\"\"\"Write out a JMA formatted storm file\n",
    "\n",
    "        :Input:\n",
    "         - *path* (string) Path to the file to be written.\n",
    "         - *verbose* (bool) Print out additional information when writing.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError((\"Writing out JMA files is not implemented \",\n",
    "                                   \"yet but is planned for a future release.\"))\n",
    "        try:\n",
    "            with open(path, 'w') as data_file:\n",
    "                for n in range(self.t.shape[0]):\n",
    "                    data_file.write(\"\".join((\"%s\" % self.seconds2date(self.t[n]),\n",
    "                                         \" \" * 4,\n",
    "                                         \"%s\" % (int(self.eye_location[n, 0] *\n",
    "                                                     10.0)),\n",
    "                                         \", \",\n",
    "                                         \"%s\" % (int(self.eye_location[n, 1] *\n",
    "                                                     10.0)),\n",
    "                                         \", \",\n",
    "                                         \"%s\" % self.max_wind_speed[n],\n",
    "                                         \", \",\n",
    "                                         \"%s\" % self.central_pressure[n],\n",
    "                                         \", \",\n",
    "                                         \", \" * 8,\n",
    "                                         \"%s\" % self.storm_radius[n],\n",
    "                                         \", \",\n",
    "                                         \"%s\" % self.max_wind_radius[n],\n",
    "                                         \", \" * 10,\n",
    "                                         \"\\n\")))\n",
    "        except Exception as e:\n",
    "            # Remove possiblly partially generated file if not successful\n",
    "            if os.path.exists(path):\n",
    "                os.remove(path)\n",
    "            raise e\n",
    "\n",
    "    def write_imd(self, path, verbose=False):\n",
    "        r\"\"\"Write out an IMD formatted storm file\n",
    "\n",
    "        :Input:\n",
    "         - *path* (string) Path to the file to be written.\n",
    "         - *verbose* (bool) Print out additional information when writing.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError((\"Writing out IMD files is not implemented \",\n",
    "                                   \"yet but is planned for a future release.\"))\n",
    "\n",
    "    def write_tcvitals(self, path, verbose=False):\n",
    "        r\"\"\"Write out an TCVITALS formatted storm file\n",
    "\n",
    "        :Input:\n",
    "         - *path* (string) Path to the file to be written.\n",
    "         - *verbose* (bool) Print out additional information when writing.\n",
    "         \"\"\"\n",
    "\n",
    "        raise NotImplementedError((\"Writing in TCVITALS files is not\",\n",
    "                                   \"implemented yet but is planned for a \",\n",
    "                                   \"future release.\"))\n",
    "\n",
    "    # =========================================================================\n",
    "    # Other Useful Routines\n",
    "    def plot(self, axes=None, intensity=False, limits=None, track_color='red',\n",
    "                   category_color=None, categorization=\"NHC\",\n",
    "                   plot_package=None):\n",
    "        r\"\"\"Plot the track and optionally the intensity of the storm\n",
    "\n",
    "        Easily plot the track and intensity of a storm using a mapping package.\n",
    "\n",
    "        :Input:\n",
    "         - *axes* (matplotlib.pyplot.axes) Axes to plot into.  Default is *None*\n",
    "         - *intensity* (bool) Plot the intensity of storm along the track.\n",
    "           Defaults to *False*.\n",
    "         - *limits* (list) Limits of the plot specified.  Defaults to either\n",
    "           using the plotting package's default or the max and min of the\n",
    "           longitude and latitude of the storm track.\n",
    "         - *track_color* (str) String or specification of plotting color to use\n",
    "           for the track if *intensity* is not being plotted.\n",
    "         - *category_color* (dict) Dictionary containing mapping between\n",
    "           category numerical value and colors.  Defaults to [0, 5] -> ['red',\n",
    "           'yellow', 'orange', 'green', 'blue', 'gray']\n",
    "         - *categorization* (str) Type of categorization, defaults to *\"NHC\"*\n",
    "         - *plot_package* (str) Package that will do the plotting.  Available\n",
    "           packages include 'cartopy', 'basemap' and 'basic'.  Checks to see\n",
    "           what packages are available if None is given.\n",
    "\n",
    "        :Output:\n",
    "         - (matplotlib.pyplot.axes) Axes object that was plotted into.\n",
    "        \"\"\"\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        # No package given, check for what is available\n",
    "        if plot_package is None:\n",
    "            # Check for cartopy\n",
    "            try:\n",
    "                import cartopy\n",
    "                plot_package = \"cartopy\"\n",
    "            except ImportError as e:\n",
    "                # Check for basemap\n",
    "                try:\n",
    "                    from mpl_toolkits.basemap import Basemap\n",
    "                    plot_package = \"basemap\"\n",
    "                except ImportError as e:\n",
    "                    plot_package = \"basic\"\n",
    "                else:\n",
    "                    warnings.warn(\"The package basemap has been EoF and is\" +\n",
    "                                  \"not available in Python 3.x.\")\n",
    "\n",
    "        # Create axes if not given\n",
    "        if axes is None:\n",
    "            fig = plt.figure()\n",
    "            axes = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "        # Set limits to the plot\n",
    "        if limits is not None:\n",
    "            warnings.warn(\"Limits to the storm track plot are not implemented.\")\n",
    "\n",
    "        # Create category dictionary mapping\n",
    "        if category_color is None:\n",
    "            category_color = {5: 'red',\n",
    "                              4: 'yellow',\n",
    "                              3: 'orange',\n",
    "                              2: 'green',\n",
    "                              1: 'blue',\n",
    "                              0: 'gray'}\n",
    "        category = self.category(categorization=categorization)\n",
    "\n",
    "        # Cartopy plotting\n",
    "        if plot_package.lower() is 'cartopy':\n",
    "            raise NotImplementedError(\"Cartopy plotting not yet implemented.\")\n",
    "\n",
    "        # Basemap plotting\n",
    "        elif plot_package.lower() is 'basemap':\n",
    "            mapping = Basemap()\n",
    "            longitude, latitude = mapping(self.eye_location[:, 0],\n",
    "                                          self.eye_location[:, 1])\n",
    "            for i in range(len(longitude)):\n",
    "                if intensity:\n",
    "                    color = category_color[category[i]]\n",
    "                else:\n",
    "                    color = track_color\n",
    "                mapping.plot(longitude[i:i + 2], latitude[i:i + 2], color=color)\n",
    "\n",
    "            mapping.drawcoastlines()\n",
    "            mapping.drawcountries()\n",
    "            mapping.fillcontinents()\n",
    "\n",
    "        # Basic plotting :-(\n",
    "        else:\n",
    "            longitude = self.eye_location[:, 0]\n",
    "            latitude = self.eye_location[:, 1]\n",
    "            for i in range(len(longitude)):\n",
    "                if intensity:\n",
    "                    color = category_color[category[i]]\n",
    "                else:\n",
    "                    color = track_color\n",
    "                axes.plot(longitude[i:i + 2], latitude[i:i + 2], color=color)\n",
    "\n",
    "            axes.set_xlabel(\"Longitude\")\n",
    "            axes.set_ylabel(\"Latitude\")\n",
    "\n",
    "        # TODO: Add colorbar for category color\n",
    "        if intensity:\n",
    "            pass\n",
    "\n",
    "        return axes\n",
    "\n",
    "    def category(self, categorization=\"NHC\", cat_names=False):\n",
    "        r\"\"\"Categorizes storm based on relevant storm data\n",
    "\n",
    "        :Input:\n",
    "         - *categorization* (string) Type of categorization to use.  Defaults\n",
    "           to the National Hurricane Center \"NHC\".\n",
    "         - *cat_names* (bool) If True returns the category name rather than a\n",
    "           number.  Default to *False*.\n",
    "\n",
    "        :Output:\n",
    "         - (ndarray) Integer array of categories at each time point of the\n",
    "           storm.\n",
    "         - (list) Similar to the above but the name of the category as a\n",
    "           *string*.  This is only returned if *car_names = True*.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO:  Need to standardize on 1-minute (almost never available) or\n",
    "        # 10-minute (widely available) - see\n",
    "        # https://en.wikipedia.org/wiki/Tropical_cyclone#Major_basins_and_related_warning_centers\n",
    "\n",
    "        if categorization.upper() == \"BEAUFORT\":\n",
    "            # Beaufort scale below uses knots\n",
    "            speeds = units.convert(self.max_wind_speed, \"m/s\", \"knots\")\n",
    "            category = (numpy.zeros(speeds.shape) +\n",
    "                        (speeds >= 1) * (speeds < 4) * 1 +\n",
    "                        (speeds >= 4) * (speeds < 7) * 2 +\n",
    "                        (speeds >= 7) * (speeds < 11) * 3 +\n",
    "                        (speeds >= 11) * (speeds < 17) * 4 +\n",
    "                        (speeds >= 17) * (speeds < 22) * 5 +\n",
    "                        (speeds >= 22) * (speeds < 28) * 6 +\n",
    "                        (speeds >= 28) * (speeds < 34) * 7 +\n",
    "                        (speeds >= 34) * (speeds < 41) * 8 +\n",
    "                        (speeds >= 41) * (speeds < 48) * 9 +\n",
    "                        (speeds >= 48) * (speeds < 56) * 10 +\n",
    "                        (speeds >= 56) * (speeds < 64) * 11 +\n",
    "                        (speeds >= 64) * 12)\n",
    "            cat_map = { 0: \"Calm\",\n",
    "                        1: \"Light air\",\n",
    "                        2: \"Light breeze\",\n",
    "                        3: \"Gentle breeze\",\n",
    "                        4: \"Moderate breeze\",\n",
    "                        5: \"Fresh breeze\",\n",
    "                        6: \"Strong breeze\",\n",
    "                        7: \"High wind\",\n",
    "                        8: \"Gale\",\n",
    "                        9: \"Strong gale\",\n",
    "                       10: \"Whole gale\",\n",
    "                       11: \"Violent storm\",\n",
    "                       12: \"Hurricane\"}\n",
    "\n",
    "        elif categorization.upper() == \"NHC\":\n",
    "            # TODO:  Change these to m/s (knots are how these are defined).\n",
    "            # Definitely not in the correct format now\n",
    "            # TODO:  Add TD and TS designations\n",
    "            speeds = units.convert(self.max_wind_speed, \"m/s\", \"knots\")\n",
    "            category = (numpy.zeros(speeds.shape) +\n",
    "                        (speeds < 30) * -1 +\n",
    "                        (speeds >= 64) * (speeds < 83) * 1 +\n",
    "                        (speeds >= 83) * (speeds < 96) * 2 +\n",
    "                        (speeds >= 96) * (speeds < 113) * 3 +\n",
    "                        (speeds >= 113) * (speeds < 135) * 4 +\n",
    "                        (speeds >= 135) * 5)\n",
    "            cat_map = {-1: \"Tropical Depression\",\n",
    "                        0: \"Tropical Storm\",\n",
    "                        1: \"Category 1 Hurricane\",\n",
    "                        2: \"Category 2 Hurricane\",\n",
    "                        3: \"Category 3 Hurricane\",\n",
    "                        4: \"Category 4 Hurricane\",\n",
    "                        5: \"Category 5 Hurricane\"}\n",
    "\n",
    "        elif categorization.upper() == \"JTWC\":\n",
    "            raise NotImplementedError(\"JTWC categorization not implemented.\")\n",
    "        elif categorization.upper() == \"JMA\":\n",
    "            raise NotImplementedError(\"JMA categorization not implemented.\")\n",
    "        elif categorization.upper() == \"IMD\":\n",
    "            raise NotImplementedError(\"IMD categorization not implemented.\")\n",
    "        elif categorization.upper() == \"MF\":\n",
    "            raise NotImplementedError(\"MF categorization not implemented.\")\n",
    "        elif categorization.upper() == \"BOM\":\n",
    "            raise NotImplementedError(\"BOM categorization not implemented.\")\n",
    "        else:\n",
    "            raise ValueError(\"Categorization %s not available.\"\n",
    "                             % categorization)\n",
    "\n",
    "        if cat_names:\n",
    "            category_name = []\n",
    "            for (i, cat) in enumerate(category):\n",
    "                category_name.append(cat_map[cat])\n",
    "\n",
    "            return category, category_name\n",
    "        else:\n",
    "            return category\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Model field construction - Models supported are\n",
    "#  - Holland 1980 ('HOLLAND_1980') [1]\n",
    "#  - Holland 2010 ('HOLLAND_2010') [2]\n",
    "#  - Chavas, Lin, Emmanuel ('CLE_2015') [3]\n",
    "# *TODO* - Add citations\n",
    "\n",
    "# Dictionary of models.  Keys are function names, values are the proper name\n",
    "# and a citation to the model\n",
    "_supported_models = {\"holland_1980\": [\"Holland 1980\", \"Holland, G. J. An Analytic Model of the Wind and Pressure Profiles in Hurricanes. Monthly Weather Review 108, 1212-1218 (1980).\"],\n",
    "                     \"holland_2010\": [\"Holland 2010\", \"Holland, G. J., Belanger, J. I. & Fritz, A. A Revised Model for Radial Profiles of Hurricane Winds. Monthly Weather Review 138, 4393-4393 (2010).\"],\n",
    "                     \"cle_2015\": [\"Chavas, Lin, Emmanuel 2015\", \"Chavas, D. R., Lin, N. & Emanuel, K. A Model for the Complete Radial Structure of the Tropical Cyclone Wind Field. Part I: Comparison with Observed Structure*. https://doi.org.ezproxy.cul.columbia.edu/10.1175/JAS-D-15-0014.1 72, 3647-3662 (2015).\"]}\n",
    "\n",
    "\n",
    "# In the case where the field is not rotationally symmetric then the r value\n",
    "# defines the x and y axis extents.\n",
    "def construct_fields(storm, r, t, model=\"holland_1980\"):\n",
    "    r\"\"\"\"\"\"\n",
    "\n",
    "    if model.lower() not in _supported_models.keys():\n",
    "        raise ValueError(\"Model %s not available.\" % model)\n",
    "\n",
    "    return getattr(sys.modules[__name__], model.lower())(storm, x, t)\n",
    "\n",
    "\n",
    "# Specific implementations\n",
    "def holland_1980(storm, r, t):\n",
    "    r\"\"\"\"\"\"\n",
    "    raise NotImplementedError(\"Holland 1980 model has not been implemeted.\")\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def holland_2010(storm, r, t):\n",
    "    r\"\"\"\"\"\"\n",
    "    raise NotImplementedError(\"Holland 2010 model has not been implemeted.\")\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def cle_2015(storm, r, t):\n",
    "    r\"\"\"\"\"\"\n",
    "    raise NotImplementedError(\"CLE 2015 model has not been implemeted.\")\n",
    "    return None, None\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Radius fill functions\n",
    "def fill_rad_w_other_source(t, storm_targ, storm_fill, var, interp_kwargs={}):\n",
    "    r\"\"\"Fill in storm radius variable (*max_wind_radius* or \\\n",
    "    *storm_radius*) with values from another source. i.e.\n",
    "    if you have missing radii in IBTrACS, you can fill with ATCF.\n",
    "    This function will assume *storm_fill* has more non-missing\n",
    "    values than *storm_targ* for this particular radius variable.\n",
    "    Thus, it first attempts to interpolate the variable in *storm_fill*\n",
    "    to the desired timestep. If that is missing, it tries to interpolate\n",
    "    the non-missing values of the variable in *storm_targ*. If that\n",
    "    also fails, it simply returns -1. The proper usage of this\n",
    "    function is to wrap it such that you can pass a function\n",
    "    with (*t*, *storm*) arguments to *max_wind_radius_fill* or\n",
    "    *storm_radius_fill* when calling *write_geoclaw*.\n",
    "\n",
    "    :Input:\n",
    "    - *t* (:py:class:`datetime.datetime`) the time corresponding to\n",
    "        a missing value of *max_wind_radius* or *storm_radius*\n",
    "    - *storm_targ* (:py:class:`clawpack.geoclaw.storm.Storm`) storm\n",
    "        that has missing values you want to fill\n",
    "    - *storm_fill* (:py:class:`clawpack.geoclaw.storm.Storm`) storm\n",
    "        that has non-missing values you want to use to fill *storm_targ*\n",
    "    - *var* (str) Either 'max_wind_radius' or 'storm_radius'\n",
    "    - *interp_kwargs* (dict) Additional keywords passed to scipy's\n",
    "        interpolator.\n",
    "\n",
    "    :Returns:\n",
    "    - (float) value to use to fill this time point in *storm_targ*. -1\n",
    "        if still missing after using *storm_fill* to fill.\n",
    "\n",
    "    :Examples:\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        >>> storm_ibtracs = Storm(file_format='IBTrACS', path='path_to_ibtracs.nc',\n",
    "        ...     sid='2018300N26315')\n",
    "\n",
    "        >>> storm_atcf = Storm(file_format='ATCF', path='path_to_atcf.dat')\n",
    "\n",
    "        >>> def fill_mwr(t, storm):\n",
    "        ...     return fill_rad_w_other_source(t, storm, storm_atcf, 'max_wind_radius')\n",
    "\n",
    "        >>> storm_ibtracs.write(file_format = 'geoclaw',\n",
    "        ...     path = 'out_path.storm',\n",
    "        ...     max_wind_radius_fill = fill_mwr)\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        import xarray as xr\n",
    "    except ImportError as e:\n",
    "        print(\"fill_rad_w_other_source currently requires xarray to work.\")\n",
    "        raise e\n",
    "\n",
    "    fill_da = xr.DataArray(getattr(storm_fill,var),\n",
    "                           coords = {'t': getattr(storm_fill,'t')},\n",
    "                           dims = ('t',))\n",
    "\n",
    "    # convert -1 to nan\n",
    "    fill_da = fill_da.where(fill_da>0,numpy.nan)\n",
    "\n",
    "    # if not all missing, try using storm_fill to fill\n",
    "    if fill_da.notnull().any():\n",
    "\n",
    "        #remove duplicates\n",
    "        fill_da = fill_da.groupby('t').first()\n",
    "\n",
    "        # remove NaNs\n",
    "        fill_da = fill_da.dropna('t')\n",
    "\n",
    "        # interpolate to point\n",
    "        fill_interp = fill_da.interp(t=[t], kwargs=interp_kwargs).item()\n",
    "\n",
    "        # try replacing with storm_fill\n",
    "        # (assuming atcf has more data points than ibtracs)\n",
    "        if not numpy.isnan(fill_interp):\n",
    "            return fill_interp\n",
    "\n",
    "    # next, try just interpolating other ibtracs values\n",
    "    targ_da = xr.DataArray(getattr(storm_targ,var),\n",
    "                              coords = {'t': getattr(storm_targ,'t')},\n",
    "                              dims = ('t',))\n",
    "    targ_da = targ_da.where(targ_da>0,numpy.nan)\n",
    "    if targ_da.notnull().any():\n",
    "        targ_da = targ_da.groupby('t').first()\n",
    "        targ_da = targ_da.dropna('t')\n",
    "        targ_interp = targ_da.interp(t=[t], kwargs=interp_kwargs).item()\n",
    "        if not numpy.isnan(targ_interp):\n",
    "            return targ_interp\n",
    "\n",
    "    # if nothing worked, return the missing value (-1)\n",
    "    return -1\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Utility functions\n",
    "def available_formats():\n",
    "    r\"\"\"Construct a string suitable for listing available storm file formats.\n",
    "    \"\"\"\n",
    "    output = \"Available Formats: (Function, Name, Citation)\\n\"\n",
    "    for (model, values) in Storm._supported_formats.items():\n",
    "        output = \"\".join((output, \"%s: %s %s\\n\" % (values[0], model,\n",
    "                                                   values[1])))\n",
    "    return output\n",
    "\n",
    "\n",
    "def available_models():\n",
    "    r\"\"\"Construct a string suitable for listing available storm models.\n",
    "    \"\"\"\n",
    "    output = \"Function, Name, Citation\\n\"\n",
    "    for (model, values) in _supported_models.items():\n",
    "        output = \"\".join((output, \"%s: %s %s\\n\" % (values[0], model,\n",
    "                                                   values[1])))\n",
    "    return output\n",
    "\n",
    "\n",
    "def make_multi_structure(path):\n",
    "    r\"\"\"Create a dictionary of Storm objects for ATCF files with multiple storm tracks in them\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        curTime = \"test\"\n",
    "        curTrack = \"test\"\n",
    "        os.mkdir(\"Clipped_ATCFs\")\n",
    "        stormDict = {}\n",
    "        for line in lines:\n",
    "            lineArr = line.split(\", \")\n",
    "            if curTime in lineArr[2]:\n",
    "                if curTrack in lineArr[4]:\n",
    "                    fileWrite.writelines(line)\n",
    "                else:\n",
    "                    fileWrite.close()\n",
    "                    stormDict[curTime].update({curTrack: Storm(path=os.path.join(os.path.expandvars(os.getcwd()), \"Clipped_ATCFs\", curTime, curTrack), file_format=\"ATCF\")})\n",
    "                    curTrack = lineArr[4]\n",
    "                    fileWrite = open(\"Clipped_ATCFs/\" + curTime + \"/\" + curTrack, 'w')\n",
    "                    fileWrite.writelines(line)\n",
    "            else:\n",
    "                if curTime != \"test\":\n",
    "                    fileWrite.close()\n",
    "                    stormDict[curTime].update({curTrack: Storm(path=os.path.join(os.path.expandvars(os.getcwd()), \"Clipped_ATCFs\", curTime, curTrack), file_format=\"ATCF\")})\n",
    "                curTime = lineArr[2]\n",
    "                curTrack = lineArr[4]\n",
    "                stormDict[curTime] = {}\n",
    "                os.mkdir(\"Clipped_ATCFs/\" + curTime)\n",
    "                fileWrite = open(\"Clipped_ATCFs/\" + curTime + \"/\" + curTrack, 'w')\n",
    "                fileWrite.writelines(line)\n",
    "    return stormDict\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Positional argument\n",
    "    parser.add_argument(\"path\", help=\"Path to storm file to be read in\")\n",
    "\n",
    "    # Optional arguments\n",
    "    parser.add_argument(\"-f\", \"--from\", default=\"atcf\", dest=\"input_format\",\n",
    "                        help=\"Format to convert from, defaults to 'atcf'\")\n",
    "    parser.add_argument(\"-o\", \"--output\", default=\"geoclaw.storm\",\n",
    "                        dest=\"output_path\",\n",
    "                        help=\"Output path, default to 'geoclaw.storm'\")\n",
    "    parser.add_argument(\"-t\", \"--to\", default=\"geoclaw\",\n",
    "                        dest=\"output_format\",\n",
    "                        help=\"Format to convert to, defaults to 'geoclaw'\")\n",
    "    parser.add_argument(\"-v\", \"--verbose\",\n",
    "                        help=\"Increase verbosity of output\",\n",
    "                        action=\"store_true\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    input_storm = Storm(args.path, file_format=args.input_format,\n",
    "                        verbose=args.verbose)\n",
    "    input_storm.write(args.output_path, file_format=args.output_format,\n",
    "                      verbose=args.verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from six.moves import range\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import numpy\n",
    "\n",
    "import clawpack.geoclaw.units as units\n",
    "import clawpack.clawutil.data\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import shutil\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from clawpack.geoclaw.surge.storm import Storm\n",
    "import clawpack.clawutil as clawutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<clawpack.geoclaw.surge.storm.Storm \"None\" at 0x7f09db58a790>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atcf_path = '/home/jovyan/data/hydroinformatics/syn_storm/bal092008.dat'\n",
    "# Uncomment/comment out to use the old version of the Ike storm file\n",
    "# ike = Storm(path=\"old_ike.storm\", file_format=\"ATCF\")\n",
    "ike = Storm(path=atcf_path, file_format=\"ATCF\")\n",
    "ike\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2008, 9, 1, 6, 0),\n",
       " datetime.datetime(2008, 9, 1, 12, 0),\n",
       " datetime.datetime(2008, 9, 1, 18, 0),\n",
       " datetime.datetime(2008, 9, 2, 0, 0),\n",
       " datetime.datetime(2008, 9, 2, 6, 0),\n",
       " datetime.datetime(2008, 9, 2, 12, 0),\n",
       " datetime.datetime(2008, 9, 2, 18, 0),\n",
       " datetime.datetime(2008, 9, 3, 0, 0),\n",
       " datetime.datetime(2008, 9, 3, 6, 0),\n",
       " datetime.datetime(2008, 9, 3, 12, 0),\n",
       " datetime.datetime(2008, 9, 3, 18, 0),\n",
       " datetime.datetime(2008, 9, 4, 0, 0),\n",
       " datetime.datetime(2008, 9, 4, 6, 0),\n",
       " datetime.datetime(2008, 9, 4, 12, 0),\n",
       " datetime.datetime(2008, 9, 4, 18, 0),\n",
       " datetime.datetime(2008, 9, 5, 0, 0),\n",
       " datetime.datetime(2008, 9, 5, 6, 0),\n",
       " datetime.datetime(2008, 9, 5, 12, 0),\n",
       " datetime.datetime(2008, 9, 5, 18, 0),\n",
       " datetime.datetime(2008, 9, 6, 0, 0),\n",
       " datetime.datetime(2008, 9, 6, 6, 0),\n",
       " datetime.datetime(2008, 9, 6, 12, 0),\n",
       " datetime.datetime(2008, 9, 6, 18, 0),\n",
       " datetime.datetime(2008, 9, 7, 0, 0),\n",
       " datetime.datetime(2008, 9, 7, 6, 0),\n",
       " datetime.datetime(2008, 9, 7, 12, 0),\n",
       " datetime.datetime(2008, 9, 7, 13, 0),\n",
       " datetime.datetime(2008, 9, 7, 18, 0),\n",
       " datetime.datetime(2008, 9, 8, 0, 0),\n",
       " datetime.datetime(2008, 9, 8, 2, 0),\n",
       " datetime.datetime(2008, 9, 8, 6, 0),\n",
       " datetime.datetime(2008, 9, 8, 12, 0),\n",
       " datetime.datetime(2008, 9, 8, 18, 0),\n",
       " datetime.datetime(2008, 9, 9, 0, 0),\n",
       " datetime.datetime(2008, 9, 9, 6, 0),\n",
       " datetime.datetime(2008, 9, 9, 12, 0),\n",
       " datetime.datetime(2008, 9, 9, 14, 0),\n",
       " datetime.datetime(2008, 9, 9, 18, 0),\n",
       " datetime.datetime(2008, 9, 10, 0, 0),\n",
       " datetime.datetime(2008, 9, 10, 6, 0),\n",
       " datetime.datetime(2008, 9, 10, 12, 0),\n",
       " datetime.datetime(2008, 9, 10, 18, 0),\n",
       " datetime.datetime(2008, 9, 11, 0, 0),\n",
       " datetime.datetime(2008, 9, 11, 6, 0),\n",
       " datetime.datetime(2008, 9, 11, 12, 0),\n",
       " datetime.datetime(2008, 9, 11, 18, 0),\n",
       " datetime.datetime(2008, 9, 12, 0, 0),\n",
       " datetime.datetime(2008, 9, 12, 6, 0),\n",
       " datetime.datetime(2008, 9, 12, 12, 0),\n",
       " datetime.datetime(2008, 9, 12, 18, 0),\n",
       " datetime.datetime(2008, 9, 13, 0, 0),\n",
       " datetime.datetime(2008, 9, 13, 6, 0),\n",
       " datetime.datetime(2008, 9, 13, 7, 0),\n",
       " datetime.datetime(2008, 9, 13, 12, 0),\n",
       " datetime.datetime(2008, 9, 13, 18, 0),\n",
       " datetime.datetime(2008, 9, 14, 0, 0),\n",
       " datetime.datetime(2008, 9, 14, 6, 0),\n",
       " datetime.datetime(2008, 9, 14, 12, 0),\n",
       " datetime.datetime(2008, 9, 14, 18, 0),\n",
       " datetime.datetime(2008, 9, 15, 0, 0),\n",
       " datetime.datetime(2008, 9, 15, 6, 0),\n",
       " datetime.datetime(2008, 9, 15, 12, 0)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ike.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 2)\n"
     ]
    }
   ],
   "source": [
    "# Reading in the storm path csv file\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy\n",
    "syn_storm_dir = '/home/jovyan/data/hydroinformatics/syn_storm/'\n",
    "syn_storm_path = os.path.join(syn_storm_dir, 'Hurricane_paths.csv') # directory for elevation profile data files\n",
    "syn_eyeloc = pd.read_csv(syn_storm_path, header = 0)\n",
    "\n",
    "\n",
    "surge_path1 = syn_eyeloc.iloc[:,0:2]\n",
    "surge_path2 = syn_eyeloc.iloc[:,2:4]\n",
    "surge_path3 = syn_eyeloc.iloc[:,4:6]\n",
    "\n",
    "print(surge_path2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f09db2cabb0>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(surge_path1.iloc[:,0], surge_path1.iloc[:,1], linewidth=2, label=\"Path1\")\n",
    "#plt.plot(surge_path2.iloc[:,0], surge_path2.iloc[:,1], linewidth=2, label=\"Path2\")\n",
    "#plt.plot(surge_path3.iloc[:,0], surge_path3.iloc[:,1], linewidth=2, label=\"Path3\")\n",
    "\n",
    "#plt.plot(surge_path2.iloc[:,1], surge_path2.iloc[:,0], linewidth=2, label=\"Path4\")\n",
    "#plt.plot(surge_path1.iloc[24,0], surge_path1.iloc[24,1], label=\"Eye_loc\", color = \"blue\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2008, 9, 1, 6, 0), datetime.datetime(2008, 9, 1, 12, 0), datetime.datetime(2008, 9, 1, 18, 0), datetime.datetime(2008, 9, 2, 0, 0), datetime.datetime(2008, 9, 2, 6, 0), datetime.datetime(2008, 9, 2, 12, 0), datetime.datetime(2008, 9, 2, 18, 0), datetime.datetime(2008, 9, 3, 0, 0), datetime.datetime(2008, 9, 3, 6, 0), datetime.datetime(2008, 9, 3, 12, 0), datetime.datetime(2008, 9, 3, 18, 0), datetime.datetime(2008, 9, 4, 0, 0), datetime.datetime(2008, 9, 4, 6, 0), datetime.datetime(2008, 9, 4, 12, 0), datetime.datetime(2008, 9, 4, 18, 0), datetime.datetime(2008, 9, 5, 0, 0), datetime.datetime(2008, 9, 5, 6, 0), datetime.datetime(2008, 9, 5, 12, 0), datetime.datetime(2008, 9, 5, 18, 0), datetime.datetime(2008, 9, 6, 0, 0), datetime.datetime(2008, 9, 6, 6, 0), datetime.datetime(2008, 9, 6, 12, 0), datetime.datetime(2008, 9, 6, 18, 0), datetime.datetime(2008, 9, 7, 0, 0), datetime.datetime(2008, 9, 7, 6, 0), datetime.datetime(2008, 9, 7, 12, 0), datetime.datetime(2008, 9, 7, 13, 0), datetime.datetime(2008, 9, 7, 18, 0), datetime.datetime(2008, 9, 8, 0, 0), datetime.datetime(2008, 9, 8, 2, 0), datetime.datetime(2008, 9, 8, 6, 0), datetime.datetime(2008, 9, 8, 12, 0), datetime.datetime(2008, 9, 8, 18, 0), datetime.datetime(2008, 9, 9, 0, 0), datetime.datetime(2008, 9, 9, 6, 0), datetime.datetime(2008, 9, 9, 12, 0), datetime.datetime(2008, 9, 9, 14, 0), datetime.datetime(2008, 9, 9, 18, 0), datetime.datetime(2008, 9, 10, 0, 0), datetime.datetime(2008, 9, 10, 6, 0), datetime.datetime(2008, 9, 10, 12, 0), datetime.datetime(2008, 9, 10, 18, 0), datetime.datetime(2008, 9, 11, 0, 0), datetime.datetime(2008, 9, 11, 6, 0), datetime.datetime(2008, 9, 11, 12, 0), datetime.datetime(2008, 9, 11, 18, 0), datetime.datetime(2008, 9, 12, 0, 0), datetime.datetime(2008, 9, 12, 6, 0), datetime.datetime(2008, 9, 12, 12, 0), datetime.datetime(2008, 9, 12, 18, 0), datetime.datetime(2008, 9, 13, 0, 0), datetime.datetime(2008, 9, 13, 6, 0), datetime.datetime(2008, 9, 13, 7, 0), datetime.datetime(2008, 9, 13, 12, 0), datetime.datetime(2008, 9, 13, 18, 0), datetime.datetime(2008, 9, 14, 0, 0), datetime.datetime(2008, 9, 14, 6, 0), datetime.datetime(2008, 9, 14, 12, 0), datetime.datetime(2008, 9, 14, 18, 0), datetime.datetime(2008, 9, 15, 0, 0), datetime.datetime(2008, 9, 15, 6, 0), datetime.datetime(2008, 9, 15, 12, 0)]\n",
      "[datetime.datetime(2008, 9, 6, 0, 0), datetime.datetime(2008, 9, 6, 6, 0), datetime.datetime(2008, 9, 6, 12, 0), datetime.datetime(2008, 9, 6, 18, 0), datetime.datetime(2008, 9, 7, 0, 0), datetime.datetime(2008, 9, 7, 6, 0), datetime.datetime(2008, 9, 7, 12, 0), datetime.datetime(2008, 9, 7, 13, 0), datetime.datetime(2008, 9, 7, 18, 0), datetime.datetime(2008, 9, 8, 0, 0), datetime.datetime(2008, 9, 8, 2, 0), datetime.datetime(2008, 9, 8, 6, 0), datetime.datetime(2008, 9, 8, 12, 0), datetime.datetime(2008, 9, 8, 18, 0), datetime.datetime(2008, 9, 9, 0, 0), datetime.datetime(2008, 9, 9, 6, 0), datetime.datetime(2008, 9, 9, 12, 0), datetime.datetime(2008, 9, 9, 14, 0), datetime.datetime(2008, 9, 9, 18, 0), datetime.datetime(2008, 9, 10, 0, 0), datetime.datetime(2008, 9, 10, 6, 0), datetime.datetime(2008, 9, 10, 12, 0), datetime.datetime(2008, 9, 10, 18, 0), datetime.datetime(2008, 9, 11, 0, 0), datetime.datetime(2008, 9, 11, 6, 0), datetime.datetime(2008, 9, 11, 12, 0), datetime.datetime(2008, 9, 11, 18, 0), datetime.datetime(2008, 9, 12, 0, 0), datetime.datetime(2008, 9, 12, 6, 0), datetime.datetime(2008, 9, 12, 12, 0), datetime.datetime(2008, 9, 12, 18, 0), datetime.datetime(2008, 9, 13, 0, 0), datetime.datetime(2008, 9, 13, 6, 0), datetime.datetime(2008, 9, 13, 7, 0)]\n",
      "[datetime.datetime(2008, 9, 6, 0, 0), datetime.datetime(2008, 9, 6, 6, 0), datetime.datetime(2008, 9, 6, 12, 0), datetime.datetime(2008, 9, 6, 18, 0), datetime.datetime(2008, 9, 7, 0, 0), datetime.datetime(2008, 9, 7, 6, 0), datetime.datetime(2008, 9, 7, 12, 0), datetime.datetime(2008, 9, 7, 13, 0), datetime.datetime(2008, 9, 7, 18, 0), datetime.datetime(2008, 9, 8, 0, 0), datetime.datetime(2008, 9, 8, 2, 0), datetime.datetime(2008, 9, 8, 6, 0), datetime.datetime(2008, 9, 8, 12, 0), datetime.datetime(2008, 9, 8, 18, 0), datetime.datetime(2008, 9, 9, 0, 0), datetime.datetime(2008, 9, 9, 6, 0), datetime.datetime(2008, 9, 9, 12, 0), datetime.datetime(2008, 9, 9, 14, 0), datetime.datetime(2008, 9, 9, 18, 0), datetime.datetime(2008, 9, 10, 0, 0), datetime.datetime(2008, 9, 10, 6, 0), datetime.datetime(2008, 9, 10, 12, 0), datetime.datetime(2008, 9, 10, 18, 0), datetime.datetime(2008, 9, 11, 0, 0), datetime.datetime(2008, 9, 11, 6, 0), datetime.datetime(2008, 9, 11, 12, 0), datetime.datetime(2008, 9, 11, 18, 0), datetime.datetime(2008, 9, 12, 0, 0), datetime.datetime(2008, 9, 12, 6, 0), datetime.datetime(2008, 9, 12, 12, 0), datetime.datetime(2008, 9, 12, 18, 0), datetime.datetime(2008, 9, 13, 0, 0), datetime.datetime(2008, 9, 13, 6, 0), datetime.datetime(2008, 9, 13, 7, 0)]\n"
     ]
    }
   ],
   "source": [
    "print(ike.t)\n",
    "ike.eye_location = ike.eye_location[19:53,]\n",
    "ike.t = ike.t[19:53]\n",
    "print(ike.t)\n",
    "ike.max_wind_speed = ike.max_wind_speed[19:53]\n",
    "ike.max_wind_radius = ike.max_wind_radius[19:53]\n",
    "ike.central_pressure = ike.central_pressure[19:53]\n",
    "ike.storm_radius = ike.storm_radius[19:53]\n",
    "#ike.time_offset = datetime.datetime(2008, 9, 13, 7)\n",
    "print(ike.t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ike.eye_location[:,0]=surge_path1.iloc[:,0]\n",
    "ike.eye_location[:,1]=surge_path1.iloc[:,1]\n",
    "geoclaw_path = '/home/jovyan/data/hydroinformatics/syn_storm/Path1.storm'\n",
    "ike.write(geoclaw_path, file_format='geoclaw')\n",
    "\n",
    "ike.eye_location[:,0]=surge_path2.iloc[:,0]\n",
    "ike.eye_location[:,1]=surge_path2.iloc[:,1]\n",
    "geoclaw_path = '/home/jovyan/data/hydroinformatics/syn_storm/Path2.storm'\n",
    "ike.write(geoclaw_path, file_format='geoclaw')\n",
    "\n",
    "ike.eye_location[:,0]=surge_path3.iloc[:,0]\n",
    "ike.eye_location[:,1]=surge_path3.iloc[:,1]\n",
    "geoclaw_path = '/home/jovyan/data/hydroinformatics/syn_storm/Path3.storm'\n",
    "ike.write(geoclaw_path, file_format='geoclaw')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate landfall time - Need to specify as the file above does not\n",
    "# include this info (9/13/2008 ~ 7 UTC)\n",
    "ike.time_offset = datetime.datetime(2008, 9, 13, 7)\n",
    "ike.write(data.storm_file, file_format='geoclaw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoclaw_path = '/home/jovyan/data/hydroinformatics/syn_storm/ike2.storm'\n",
    "ike = Storm(path=geoclaw_path, file_format='geoclaw')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_for_geoclaw]",
   "language": "python",
   "name": "conda-env-env_for_geoclaw-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
